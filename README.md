# User Guide: Preprocessing, Geocoding, Clustering, and Optimization Scripts

This repository contains a set of Python scripts developed to preprocess wildlife surveillance data, perform geocoding, execute spatial‚Äìtemporal clustering, and generate cluster-level features for downstream analysis and index optimization. These scripts support the experiments described in the manuscript:

‚ÄúAn index-based system for early alerts of potential zoonotic disease outbreaks‚Äù (submitted to PLOS ONE).

The pipelines were designed for reproducibility and are organized into sequential steps.


## üìÇ Repository Structure

```bash
.
‚îú‚îÄ‚îÄ data_plos/                 # Folder for inputs and outputs  
‚îú‚îÄ‚îÄ 01_1_pre_process.py        # Preprocessing script  
‚îú‚îÄ‚îÄ 01_2_geocoding.py          # Geocoding script  
‚îú‚îÄ‚îÄ 02_spatiotemporal_clustering.py   # DBSCAN clustering  
‚îú‚îÄ‚îÄ 03_1_cluster_characterization.py  # Cluster characterizaation  
‚îú‚îÄ‚îÄ 04_mo_optimization.py             # Multi-objective optimization 
‚îî‚îÄ‚îÄ README.md  
```


## üîß Required packages

These scripts were developed using **Python 3.10+**.

Required packages include:

- `pandas`
- `numpy`
- `geopandas`
- `scikit-learn`
- `shapely`
- `geopy`
- `matplotlib` (optional)
- `scipy`

## üìú Script Descriptions

### 1. **01_1_pre_process.py**
This script is responsible for the initial preprocessing of the input CSV file.

- **Main function:** `preprocess_data(input_csv)`
  - **Description:** Renames the columns, converts the date column to datetime format, and applies filters to remove low-precision data.
  - **Parameters:** `input_csv` (path to the input CSV file).
  - **Output:** A new CSV file is created in the `data_plos` folder with cleaned and filtered records.

### 2. **01_2_geocoding.py**
This script assigns geolocation codes (geocodes) to records using IBGE shapefiles.

This script was used only for generating data in the experiments related to NHPs, due to the need for geocoding records to compare them with the Ministry of Health database for confirmed Yellow Fever cases.

- **Main function:** `geocode_data(input_csv, output_csv_7d, output_csv_6d, mun_shp, uf_shp)`
  - **Description:** Performs a spatial join between the record coordinates and the municipality and state polygons from IBGE shapefiles. It adds columns for geocode, municipality, and state. The script generates two output files: one with 7‚Äëdigit geocodes and another with 6‚Äëdigit geocodes.
  - **Parameters:**
    - `input_csv`: Path to the input CSV file (generated by the previous script).
    - `output_csv_7d`: Path for saving the file with 7‚Äëdigit geocodes.
    - `output_csv_6d`: Path for saving the file with 6‚Äëdigit geocodes.
    - `mun_shp`: Path to the municipality shapefile.
    - `uf_shp`: Path to the state shapefile.
  - **Output:** Two CSV files are created in the `data_plos` folder:
    - `...filtrado_limpo_geocode.csv` (7‚Äëdigit geocodes)
    - `...filtrado_limpo_geocode_6d.csv` (6‚Äëdigit geocodes)

### 3. **02_spatiotemporal_clustering.py**
This script performs clustering based on spatial and temporal proximity using the DBSCAN algorithm.

- **Main function:** `cluster_records(input_csv, output_csv, matrix_output_folder, time_limit, distance_limit)`
  - **Description:** Computes distance and time matrices between all record pairs. Then it normalizes and combines these matrices to create a total distance matrix. DBSCAN is executed twice with different parameters (`min_samples = 1` and `min_samples = 2`), producing two cluster columns (`Cluster1` and `Cluster2`).
  - **Parameters:**
    - `input_csv`: Path to the input CSV file (generated by the previous script).
    - `output_csv`: Path to save the output CSV file containing the cluster assignments.
    - `matrix_output_folder`: Folder to save the distance, time, and total matrices.
    - `time_limit`: Time threshold (in days) for records to be considered close.
    - `distance_limit`: Distance threshold (in km) for records to be considered close.
  - **Output:**
    - A new CSV file `clusters_30d_1km.csv` in the `data_plos` folder with clustering results.
    - Distance, time, and total distance matrices saved as CSV files in `data_plos/distance_matrix`.

### 4. **03_1_cluster_characterization.py**
This script characterizes the clusters generated by `03_clustering.py`. It takes as input the CSV file containing cluster assignments (`Cluster1` and `Cluster2`) and produces a new CSV with summarized attributes for each cluster.

- **Main function:** `calculate_cluster_characteristics(input_csv, output_csv)`
  - **Description:** The algorithm performs the following steps for each cluster:
    - **Data Loading and Preparation:** Reads the input CSV and converts the date column to datetime.
    - **Data Standardization:** Standardizes values in the `d_classificacao` and `d_doenca` columns for consistency.
    - **Feature Calculation:** Groups data by cluster (`Cluster1`) and computes various metrics, including:
      - Total number of animals.
      - Count of records labeled as 'dead' and 'alive'.
      - Count of records by behavioral category ('Normal', 'Sick', 'Strange', 'Aggressive').
      - Time interval (in days) between the first and last observations in the cluster.
      - Spatial extent (in km), calculated as the geodesic distance between the farthest points within the cluster.
      - Presence or absence of disease records or confirmed cases.
      - **Frequencies and Percentages:** Frequency of records and animals per day, and percentages of deaths and other behaviors relative to the total number of animals.
  - **Output:**
    - Saves a final DataFrame with one row per cluster, containing all calculated characteristics, into a new CSV file.

### 5. **04_mo_optimization.py**
This script performs **multi-objective optimization** to compute optimal weights for the Alert Index using a Pareto‚Äëbased approach. 

- **Main components:**
  - **Description:** The script loads the cluster characterization file, standardizes and normalizes all relevant attributes, filters the dataset to include only clusters containing confirmed cases, and applies a multi-objective optimization using the SLSQP algorithm.  Two objectives are evaluated for each weight configuration:
    - (1) maximize the average alert index in confirmed clusters;
    - (2) minimize the variance of the index across all clusters.
      
    The optimization is repeated for multiple values of the trade-off parameter Œ± (0 to 1), generating a Pareto-like set of solutions. The script outputs the optimal weight vectors, objective values, and a baseline comparison using uniform weights.
  - **Output:**
    - Normalized and standardized files saved in `data_plos/`.
    - A printed table summarizing optimal weights and objective values for each `alpha`.
    - A final comparison with uniform weights (baseline model).
 
